{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "data=sio.loadmat('spikewave.mat')\n",
    "\n",
    "print(data)\n",
    "spike_data=data['wave']\n",
    "print(spike_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先引入我们需要用到的库，由于该数据表示5376种波的40个采样点\n",
    "所以先用spike_data1保存原数据的转置，而后进行操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_data1 = spike_data.T\n",
    "print(spike_data1.shape)\n",
    "plt.figure(figsize=(50,20))\n",
    "for i in range(5376):\n",
    "    plt.plot(spike_data1[i])\n",
    "\n",
    "plt.title('spike_wawes')\n",
    "plt.xlabel('Sample points')\n",
    "plt.ylabel('Amplitude')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "问题1：把这些 spike 波形叠画在一起，观察并描述它们的可分性"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "肉眼可见的难以辨别，5k多条线在同一张图上实属密集，可分性不高，太密集啦\n",
    "\n",
    "不同波的走势差异性并不是很强，难以进行划分\n",
    "\n",
    "不妨先画几种波，浅浅分析一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,20))\n",
    "for i in range(10):\n",
    "    plt.plot(spike_data1[i])\n",
    "\n",
    "plt.title('spike_wawes1')\n",
    "plt.xlabel('Sample points')\n",
    "plt.ylabel('Amplitude')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个图中可以看到，这10种波还是有一定区别的：\n",
    "\n",
    "1、不同的波起点不同，峰值和谷值不同且峰值和谷值出现的时间各不相同。\n",
    "\n",
    "2、这几种波在靠后的时间趋于平缓\n",
    "\n",
    "我们再看看其他几种波"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,20))\n",
    "for i in range(5366,5376):\n",
    "    plt.plot(spike_data1[i])\n",
    "\n",
    "plt.title('spike_wawes2')\n",
    "plt.xlabel('Sample points')\n",
    "plt.ylabel('Amplitude')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，这10种波的可分性更大了一些：\n",
    "\n",
    "部分波整体都比较平缓，峰值和谷值绝对值的差相对较小，而有些波峰值和谷值绝对值的差很大。\n",
    "\n",
    "另外，我们观察图spike_wave可以发现，还有些波在靠后的采样点峰值和谷值出现的频率较高，也就是波动比较大，这一点与我们目前分析的靠前采样点波动大而靠后采样点波动小是不同的。\n",
    "\n",
    "至此，问题1回答完毕。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在5376种波里随机选取10条并绘制，发现每次绘制选取的10条波，差异程度均有所不同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,20))\n",
    "array = np.random.randint(0,5376,10)#产生n--m之间的k个整数\n",
    "for i in array:\n",
    "    plt.plot(spike_data1[i])\n",
    "plt.title('spike_wawes3')\n",
    "plt.xlabel('Sample points')\n",
    "plt.ylabel('Amplitude')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们来讨论问题2：用 PCA 方法把这些 spike 分别降维到 2 维和 3 维空间，并画出来"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查阅了一些参考资料：\n",
    "\n",
    "[参考资料_1_降维——PCA](https://zhuanlan.zhihu.com/p/77151308)\n",
    "\n",
    "[参考链接_2_python实现PCA](https://finthon.com/python-pca/)\n",
    "\n",
    "链接1具体讲述了PCA方法是如何实现降维的，有助于我们理解PCA方法的原理，链接2则侧重于实现，通过python采用numpy和PCA的scikit-learn实现，下面主要根据链接2来实现spike_waves的降维工作。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其他参考链接：\n",
    "\n",
    "[参考1](https://www.cnblogs.com/pinard/p/6239403.html)\n",
    "\n",
    "[参考2](https://www.jianshu.com/p/5a6925b161bc)\n",
    "\n",
    "参考2需要再去研读一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#创建PCA对象1，降维到2维空间\n",
    "pca1 = PCA(n_components = 2)\n",
    "\n",
    "#对数据进行转换拟合\n",
    "spike_waves_2d = pca1.fit_transform(spike_data1)\n",
    "\n",
    "#打印出数据\n",
    "print(spike_waves_2d)\n",
    "\n",
    "plt.figure(figsize = (30,20))\n",
    "#设定第1维做x轴，第2维做y轴\n",
    "plt.scatter(spike_waves_2d[:,0],spike_waves_2d[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "#%matplotlib inline----解决<Figure size 640x480 with 1 Axes>\n",
    "#创建PCA对象2，降维到3维空间\n",
    "pca2 = PCA(n_components = 3)\n",
    "\n",
    "#对数据进行转换拟合\n",
    "spike_waves_3d = pca2.fit_transform(spike_data1)\n",
    "\n",
    "#打印出数据\n",
    "#print(spike_waves_3d)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "#ax = Axes3D(fig)\n",
    "ax = Axes3D(fig,auto_add_to_figure=False)\n",
    "fig.add_axes(ax)\n",
    "#ax=fig.add_subplot(111,projection='3d')\n",
    "#设定第1维做x轴，第2维做y轴,第3维做z轴\n",
    "plt.scatter(spike_waves_3d[:,0],spike_waves_3d[:,1],spike_waves_3d[:,2])\n",
    "#ax.scatter(spike_waves_3d[:,0],spike_waves_3d[:,1],spike_waves_3d[:,2],s=8)\n",
    "#plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出现了一些问题……换个方式重来\n",
    "\n",
    "上面这个图点点有亿点点大\n",
    "\n",
    "太奇怪了啊啊啊啊啊\n",
    "\n",
    "原因是因为python3.4以后把语句ax = Axes3D(fig)淘汰掉了，换成现在代码中的部分，就解决啦\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[参考链接_1](https://www.jianshu.com/p/b563920fa7a8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建PCA对象2，降维到3维空间\n",
    "pca2 = PCA(n_components = 3)\n",
    "\n",
    "#对数据进行转换拟合\n",
    "spike_waves_3d = pca2.fit_transform(spike_data1)\n",
    "\n",
    "#打印出数据\n",
    "#print(spike_waves_3d)\n",
    "\n",
    "fig = plt.figure(figsize=(10,15))\n",
    "#设定第1维做x轴，第2维做y轴,第3维做z轴\n",
    "ax=fig.add_subplot(111,projection='3d')\n",
    "#ax = Axes3D(fig)\n",
    "ax.scatter(spike_waves_3d[:,0],spike_waves_3d[:,1],spike_waves_3d[:,2])\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此，问题2回答完毕。\n",
    "\n",
    "问题3：在 2 维和 3 维空间分别采用合适的聚类方法把它们分成合理类别，这些类别就对应于临近的神经细胞放电。 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[参考资料_1_K-means算法](https://blog.csdn.net/fztsilly/article/details/113817397)\n",
    "\n",
    "根据参考资料中的代码，将输入改为我们用PCA方法降维的二维数据并进行聚类，得到如下结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(e1, e2):\n",
    "    return np.sqrt((e1[0] - e2[0]) ** 2 + (e1[1] - e2[1]) ** 2)\n",
    "\n",
    "\n",
    "def means(arr):\n",
    "    return np.array([np.mean([e[0] for e in arr]), np.mean([e[1] for e in arr])])\n",
    "\n",
    "\n",
    "def farthest(k_arr, arr):\n",
    "    f = [0, 0]\n",
    "    max_d = 0\n",
    "    for e in arr:\n",
    "        d = 0\n",
    "        for i in range(k_arr.__len__()):\n",
    "            d = d + np.sqrt(distance(k_arr[i], e))\n",
    "        if d > max_d:\n",
    "            max_d = d\n",
    "            f = e\n",
    "    return f\n",
    "\n",
    "\n",
    "def closest(a, arr):\n",
    "    c = arr[1]\n",
    "    min_d = distance(a, arr[1])\n",
    "    arr = arr[1:]\n",
    "    for e in arr:\n",
    "        d = distance(a, e)\n",
    "        if d < min_d:\n",
    "            min_d = d\n",
    "            c = e\n",
    "    return c\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    arr = spike_waves_2d\n",
    "    #这里就已经实现聚类了\n",
    "    m = 4   #聚类的中心点个数\n",
    "    r = np.random.randint(arr.__len__() - 1)\n",
    "    k_arr = np.array([arr[r]])\n",
    "    cla_arr = [[]]\n",
    "    for i in range(m - 1):\n",
    "        k = farthest(k_arr, arr)\n",
    "        k_arr = np.concatenate([k_arr, np.array([k])])\n",
    "        cla_arr.append([])\n",
    "\n",
    "    n = 20\n",
    "    cla_temp = cla_arr\n",
    "    for i in range(n):\n",
    "        for e in arr:\n",
    "            ki = 0\n",
    "            min_d = distance(e, k_arr[ki])\n",
    "            for j in range(1, k_arr.__len__()):\n",
    "                if distance(e, k_arr[j]) < min_d:\n",
    "                    min_d = distance(e, k_arr[j])\n",
    "                    ki = j\n",
    "            cla_temp[ki].append(e)\n",
    "\n",
    "        for k in range(k_arr.__len__()):\n",
    "            if n - 1 == i:\n",
    "                break\n",
    "            k_arr[k] = means(cla_temp[k])\n",
    "            cla_temp[k] = []\n",
    "\n",
    "    col = ['HotPink', 'Aqua', 'Chartreuse', 'yellow', 'LightSalmon','red']\n",
    "    #col = ['HotPink', 'Aqua', 'Chartreuse', 'yellow']\n",
    "    for i in range(m):\n",
    "        plt.scatter(k_arr[i][0], k_arr[i][1], linewidth=10, color=col[i])\n",
    "        plt.scatter([e[0] for e in cla_temp[i]], [e[1] for e in cla_temp[i]], color=col[i],s=5)\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "继续查阅资料发现sklearn中有包装好的K-means包，以下实现方式是直接采用已封装好的KMeans来实现\n",
    "\n",
    "[参考资料_2_K-means聚类](https://blog.51cto.com/liangdongchang/3120268)\n",
    "\n",
    "[参考资料_3_python实现聚类分析和数据降维](https://developer.aliyun.com/article/1123835)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1、导包\n",
    "from sklearn.cluster import KMeans\n",
    "%matplotlib inline\n",
    "\n",
    "#2、初始化数据\n",
    "X = spike_waves_2d\n",
    "plt.scatter(X[:,0],X[:,1],s=8)\n",
    "\n",
    "#3、找到，并绘制中心点（此处我们选择的中值数量为4）\n",
    "#选取4个种子\n",
    "km4 = KMeans(n_clusters=4)\n",
    "# 无监督学习：estimator.fit(X)\n",
    "# 监督学习：estimator.fit(X,y)\n",
    "#我们采用无监督学习方式，拟合的时候不需要样本标签\n",
    "km4.fit(X)\n",
    "\n",
    "#查看聚类中心坐标点\n",
    "cluster_centers_ = km4.cluster_centers_\n",
    "print(cluster_centers_)\n",
    "\n",
    "#显示聚类中心\n",
    "plt.scatter(X[:,0],X[:,1],s=8)\n",
    "plt.scatter(cluster_centers_[:,0],cluster_centers_[:,1],s=30,alpha=0.4,c='r')\n",
    "\n",
    "#4、用不同颜色表示不同的类别\n",
    "\n",
    "#可以看到与上述我们没有用包，直接计算得来的分类结果差不多\n",
    "y_predict2_4 = km4.predict(X)  # 预测\n",
    "plt.scatter(X[:,0],X[:,1],c=y_predict2_4,s=8)  # 预测为同一簇的样本同颜色\n",
    "plt.show()\n",
    "\n",
    "#5、若分为5类，又是另一种结果\n",
    "# 创建KMeans算法对象，设置聚成5类\n",
    "km5 = KMeans(n_clusters=5,random_state=666) \n",
    "km5.fit(X) # 无监督学习，拟合的时候不需要样本标签\n",
    "y_predict2_5 = km5.predict(X)  # 预测\n",
    "plt.scatter(X[:,0],X[:,1],c=y_predict2_5,s=8)  # 预测为同一簇的样本同颜色\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们对三维数据进行聚类分析\n",
    "\n",
    "[参考链接](https://blog.csdn.net/sgld995/article/details/108390774?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522168778917216800215030551%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=168778917216800215030551&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-108390774-null-null.142^v88^control_2,239^v2^insert_chatgpt&utm_term=%E4%B8%89%E7%BB%B4%E6%95%B0%E6%8D%AE%E8%81%9A%E7%B1%BB&spm=1018.2226.3001.4187)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from sklearn import preprocessing\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "# 标准化数据集 \n",
    "\n",
    "def normalize(X, axis=-1, p=2):\n",
    "    lp_norm = np.atleast_1d(np.linalg.norm(X, p, axis))\n",
    "    lp_norm[lp_norm == 0] = 1\n",
    "    return X / np.expand_dims(lp_norm, axis)\n",
    "\n",
    "\n",
    "# 计算一个样本与数据集中所有样本的欧氏距离的平方\n",
    "def euclidean_distance(one_sample, X):\n",
    "    one_sample = one_sample.reshape(1, -1)\n",
    "    X = X.reshape(X.shape[0], -1)\n",
    "    distances = np.power(np.tile(one_sample, (X.shape[0], 1)) - X, 2).sum(axis=1)\n",
    "    return distances\n",
    "\n",
    "\n",
    "class Kmeans():\n",
    "    def __init__(self, k=4, max_iterations=500, varepsilon=0.0001):\n",
    "        self.k = k\n",
    "        self.max_iterations = max_iterations\n",
    "        self.varepsilon = varepsilon\n",
    "\n",
    "    # 从所有样本中随机选取self.k样本作为初始的聚类中心\n",
    "    def init_random_centroids(self, X):\n",
    "        n_samples, n_features = np.shape(X)\n",
    "        centroids = np.zeros((self.k, n_features))\n",
    "        for i in range(self.k):\n",
    "            centroid = X[np.random.choice(range(n_samples))]\n",
    "            centroids[i] = centroid\n",
    "        return centroids\n",
    "\n",
    "    # 返回距离该样本最近的一个中心索引[0, self.k)\n",
    "    def _closest_centroid(self, sample, centroids):\n",
    "        distances = euclidean_distance(sample, centroids)\n",
    "        closest_i = np.argmin(distances)\n",
    "        return closest_i\n",
    "\n",
    "    # 将所有样本进行归类，归类规则就是将该样本归类到与其最近的中心\n",
    "    def create_clusters(self, centroids, X):\n",
    "        n_samples = np.shape(X)[0]\n",
    "        clusters = [[] for _ in range(self.k)]\n",
    "        for sample_i, sample in enumerate(X):\n",
    "            centroid_i = self._closest_centroid(sample, centroids)\n",
    "            clusters[centroid_i].append(sample_i)\n",
    "        return clusters\n",
    "\n",
    "    # 对中心进行更新\n",
    "    def update_centroids(self, clusters, X):\n",
    "        n_features = np.shape(X)[1]\n",
    "        centroids = np.zeros((self.k, n_features))\n",
    "        for i, cluster in enumerate(clusters):\n",
    "            centroid = np.mean(X[cluster], axis=0)\n",
    "            centroids[i] = centroid\n",
    "        return centroids\n",
    "\n",
    "    # 将所有样本进行归类，其所在的类别的索引就是其类别标签\n",
    "    def get_cluster_labels(self, clusters, X):\n",
    "        y_pred = np.zeros(np.shape(X)[0])\n",
    "        for cluster_i, cluster in enumerate(clusters):\n",
    "            for sample_i in cluster:\n",
    "                y_pred[sample_i] = cluster_i\n",
    "        return y_pred\n",
    "\n",
    "    # 对整个数据集X进行Kmeans聚类，返回其聚类的标签\n",
    "    def predict(self, X):\n",
    "        # 从所有样本中随机选取self.k样本作为初始的聚类中心\n",
    "        centroids = self.init_random_centroids(X)\n",
    "\n",
    "        # 迭代，直到算法收敛(上一次的聚类中心和这一次的聚类中心几乎重合)或者达到最大迭代次数\n",
    "        for _ in range(self.max_iterations):\n",
    "            # 将所有进行归类，归类规则就是将该样本归类到与其最近的中心\n",
    "            clusters = self.create_clusters(centroids, X)\n",
    "            former_centroids = centroids\n",
    "\n",
    "            # 计算新的聚类中心\n",
    "            centroids = self.update_centroids(clusters, X)\n",
    "\n",
    "            # 如果聚类中心几乎没有变化，说明算法已经收敛，退出迭代\n",
    "            diff = centroids - former_centroids\n",
    "            if diff.any() < self.varepsilon:\n",
    "                break\n",
    "\n",
    "        return self.get_cluster_labels(clusters, X)\n",
    "# 读取数据\n",
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "A = np.array(spike_waves_3d)\n",
    "X=min_max_scaler.fit_transform(A)\n",
    "num, dim = X.shape\n",
    "clf = Kmeans(k=4)\n",
    "y_predict3_4 = clf.predict(X)\n",
    "print(y_predict3_4)\n",
    "color = ['HotPink', 'Aqua', 'Chartreuse', 'yellow', 'LightSalmon','red']\n",
    "ax = plt.subplot(111, projection='3d')\n",
    "\n",
    "for p in range(0,num):\n",
    "    y=y_predict3_4[p]\n",
    "    ax.scatter(int(A[p, 0]), int(A[p, 1]), int(A[p, 2]), c=color[int(y)])\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此，问题3回答完毕\n",
    "\n",
    "问题四：把 Spike sorting 之后的波形按照神经细胞归类，用不同颜色再次叠画在一起，观察并描述它们的波形在类内和类间的差异\n",
    "\n",
    "我下面将按照K-means对二维数据的4聚类分类结果来绘制波形图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取不同类别的索引\n",
    "unique_clusters = np.unique(y_predict2_4)\n",
    "\n",
    "# 设置颜色映射，每个类别对应不同的颜色\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(unique_clusters)))\n",
    "\n",
    "# 绘制波形图\n",
    "fig, ax = plt.subplots()\n",
    "for i, y in enumerate(unique_clusters):\n",
    "    mask = y_predict2_4 == y\n",
    "    ax.plot(spike_data1[mask].T, color=colors[i])\n",
    "\n",
    "ax.set_xlabel('SamplePoints')\n",
    "ax.set_ylabel('Amplitude')\n",
    "ax.set_title('spike_data by Cluster')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "观察波形在类间的差异：发现不同类型的波形在时刻0-8以及8-14左右差异明显，但是到了15以后，差异变得不那么突出了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单独绘制每个聚类簇的图形\n",
    "for i, y in enumerate(unique_clusters):\n",
    "    mask = y_predict2_4 == y\n",
    "    cluster_data = spike_data1[mask]\n",
    "\n",
    "    # 创建一个新的图形窗口\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # 绘制每个聚类簇的数据\n",
    "    for data in cluster_data:\n",
    "        ax.plot(data, color=colors[i])\n",
    "\n",
    "    ax.set_xlabel('SamplePoints')\n",
    "    ax.set_ylabel('Amplitude')\n",
    "    ax.set_title(f'spike_data for Cluster {y_predict2_4}')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "观察类内之间的差异：发现每种波形他们在0-15刻相互之间差异并不是很大，波动较小，但是15刻之后差异变得非常明显，表现为纵轴跨越度大。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
